{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "The purpose of this notebook is to demonstrate the basic workings of a) the Learning in the Model Space (LiMS) Probabilistic Hough Transform (PHT) classifier\n",
    "and b) the subspace learning algorithm, both presented in \"Discriminative subspace learning for model- and data-driven discovery\"\n",
    "\n",
    "The notebook is structured as follows\n",
    "1. Data generation and visualization\n",
    "2. Sampling of posteriors\n",
    "3. Density estimation\n",
    "4. Evaluating the LiMS PHT classifier\n",
    "5. Subspace learning\n",
    "\n",
    "Depending on the device available, the sampling of posteriors (Step 3) and performing the density estimation (Step 4) may take quite a while.\n",
    "Therefore, the number of example timeseries created is restricted to 5 examples for steps 1, 2 and 3.\n",
    "Before step 4, the user can choose to either proceed with the data set thus created (5 examples per class) or\n",
    "load a dataset from a previous run of sampling with 40 examples per class (as reported in the paper).\n",
    "\n",
    "Cells that take a bit longer to run have an indication of how long it took on a Laptop with an AMD Ryzen 7 5800H processor, 16 GB RAM and a NVIDIA GeForce RTX 3070 graphics card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant packages and modules\n",
    "import numpy as np\n",
    "from src.dynamical_systems.prednisone_3D import Prednisone3D\n",
    "from src.sampler import Sampler\n",
    "from src.data_box import DataBox\n",
    "from src.density_estimator import DensityEstimator\n",
    "from src.lims_classifier import LiMSClassifier\n",
    "import src.utility as utility\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from src.subspace_learner import SubspaceLearner\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Data generation and visualization\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data set\n",
    "\n",
    "model = Prednisone3D()\n",
    "\n",
    "gen_data_opts = {\n",
    "    'num_examples': np.array([5, 5]),                        # Array with number of examples per class\n",
    "    'init_cond': np.array([0, 0]),                           # Array holding intial condition for prednisone model (P0: prednisone in blood, L0: prednisolone in blood)\n",
    "    't_lim': np.array([0, 240]),                             # Array holding minimal and maximal time values t_min and t_max\n",
    "    'obs_regularity': np.array([10, 15]),                    # Array holding the minimum and maximum amount of time steps between t_min and t_max\n",
    "    'obs_noise_cov': np.diag([20, 20]),                      # Array holding the cov. matrix for observational noise to be added to P and L trajectories\n",
    "    'scale_spiral': 0.15,                                    # Number giving the scaling of the sprial structure that characterizes the class-conditionals\n",
    "    'sigma_orth_comp': 0.05,                                 # Positive Number, giving the std. of Gaussian components orthogonal to spiral\n",
    "    'shift_vec': np.array([0.1, 0.1, 0.1]),                  # Array giving the shift of the spiral center \n",
    "    'rot_angles': [-np.pi / 4, 0., 0.]                       # List containing the x, y and z rotation angles\n",
    "}\n",
    "\n",
    "data_box_t = model.gen_timeseries_data_rotated_spiral(gen_data_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize parameters\n",
    "\n",
    "# get labels and class indices\n",
    "labels = data_box_t.get_labels()\n",
    "idx_C0 = [idx for idx, value in enumerate(labels) if value == 0]\n",
    "idx_C1 = [idx for idx, value in enumerate(labels) if value == 1]\n",
    "\n",
    "# get parameters and separate by class\n",
    "parameters = data_box_t.get_parameters()\n",
    "params_C0 = parameters[idx_C0, :]\n",
    "params_C1 = parameters[idx_C1, :]\n",
    "\n",
    "# get true subspace\n",
    "subspace = data_box_t.get_subspace()\n",
    "center = subspace['center']\n",
    "v1 = 0.1 * subspace['v1']\n",
    "v2 = 0.1 * subspace['v2']\n",
    "\n",
    "# visualize the groundtruth parameters\n",
    "%matplotlib widget \n",
    "\n",
    "# create the plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(params_C0[:, 0], params_C0[:, 1], params_C0[:, 2], c='blue')\n",
    "ax.scatter(params_C1[:, 0], params_C1[:, 1], params_C1[:, 2], c='red')\n",
    "\n",
    "ax.plot([center[0], center[0] + v1[0]], [center[1], center[1] + v1[1]], zs=[center[2], center[2] + v1[2]], color='g')\n",
    "ax.plot([center[0], center[0] + v2[0]], [center[1], center[1] + v2[1]], zs=[center[2], center[2] + v2[2]], color='y')\n",
    "\n",
    "ax.scatter(0, 0, 0, color='k', linewidths=2)\n",
    "\n",
    "ax.set_xlim([0, 0.2])\n",
    "ax.set_ylim([0, 0.2])\n",
    "ax.set_zlim([0, 0.2])\n",
    "\n",
    "ax.set_xlabel('k_abs')\n",
    "ax.set_ylabel('k_PL')\n",
    "ax.set_zlabel('k_LP')\n",
    "ax.set_title('Parameters used for data generation')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot generated time series data\n",
    "\n",
    "timeseries = data_box_t.get_timeseries()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "for i in range(len(idx_C0)):\n",
    "    if i == 0:\n",
    "        label = label='class 0'\n",
    "    else:\n",
    "        label = None\n",
    "    axs[0].plot(timeseries[idx_C0[i]][0, :], timeseries[idx_C0[i]][1, :], color='blue', alpha=0.2, label=label)\n",
    "    axs[1].plot(timeseries[idx_C0[i]][0, :], timeseries[idx_C0[i]][2, :], color='blue', alpha=0.2)\n",
    "\n",
    "\n",
    "for i in range(len(idx_C1)):\n",
    "    if i == 0:\n",
    "        label = label='class 1'\n",
    "    else:\n",
    "        label = None\n",
    "    axs[0].plot(timeseries[idx_C1[i]][0, :], timeseries[idx_C1[i]][1, :], color='red', alpha=0.2, label=label)\n",
    "    axs[1].plot(timeseries[idx_C1[i]][0, :], timeseries[idx_C1[i]][2, :], color='red', alpha=0.2)\n",
    "\n",
    "\n",
    "axs[0].set_xlabel('t')\n",
    "axs[0].set_ylabel('P(t)')\n",
    "axs[0].set_xlim(0, 240)\n",
    "axs[0].set_ylim(0, 180)\n",
    "axs[0].set_title('Prednisone')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_xlabel('t')\n",
    "axs[1].set_ylabel('L(t)')\n",
    "axs[1].set_xlim(0, 240)\n",
    "axs[1].set_ylim(0, 180)\n",
    "axs[1].set_title('Prednisolone')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Sampling of posteriors\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sampler and run (~ 1 minute runtime)\n",
    "\n",
    "# set sampler options\n",
    "sampler_opts = {\n",
    "    'type': 'nested_sampling',\n",
    "    'num_live_points': 50,\n",
    "    'parallel': True,\n",
    "    'num_CPU': 8,\n",
    "    'weighted': False\n",
    "}\n",
    "\n",
    "# define sampler object\n",
    "sampler = Sampler(data_box_t, sampler_opts)\n",
    "\n",
    "# run sampling\n",
    "data_box_ts = sampler.run_sampling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize created samples\n",
    "\n",
    "num_bins = 100\n",
    "smoothness = 1\n",
    "colours = ['blue', 'red', 'green']\n",
    "labels=[r\"$m_{1}$\",\n",
    "        r\"$m_{2}$\",\n",
    "        r\"$s_{1}$\",\n",
    "        r\"$s_{2}$\"]\n",
    "limits = np.array([[0, 100],\n",
    "                   [0, 100],\n",
    "                   [-1, 1],\n",
    "                   [-1, 1],])\n",
    "\n",
    "title = 'Gravitational Waves'\n",
    "legend = ['NS - BH / NS - NS', 'Small BH - Small BH', 'Large BH - Large BH ']\n",
    "figsize = (15, 6)\n",
    "\n",
    "figure = data_box_ts.plot_posterior_samples(\n",
    "                                            num_bins = 100, \n",
    "                                            smoothness = 1, \n",
    "                                            colours = ['blue', 'red'],\n",
    "                                            labels=[r\"$k_{abs}$\", r\"$k_{PL}$\", r\"$k_{LP}$\"], \n",
    "                                            limits=np.array([[0, 0.2],\n",
    "                                                             [0, 0.2],\n",
    "                                                             [0, 0.2]]), \n",
    "                                            title='Samples', \n",
    "                                            legend=['class 0', 'class 1'], \n",
    "                                            figsize=(10, 10)\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Density estimation\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create density estimates with spherical covariance structure (~ 4 seconds)\n",
    "\n",
    "# set density estimation options\n",
    "density_est_opts = {\n",
    "    'type':             'bayesian_gaussian_mixture',\n",
    "    'covariance_type':                  'spherical',    # 'full' 'spherical' \n",
    "    'n_components':                               5,    # 20 \n",
    "    'n_init' :                                   20,    # 20\n",
    "    'max_iter':                                 500,    # 500\n",
    "    'trim_percent':                            0.99\n",
    "}\n",
    "\n",
    "# define density estimator object\n",
    "dens_estimator = DensityEstimator(data_box_ts, density_est_opts)\n",
    "\n",
    "# run density estimation\n",
    "data_box_spherical = dens_estimator.run_density_estimation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize density estimates\n",
    "plot_opts = {\n",
    "'x_lim':        np.array([0, 0.2]),\n",
    "'y_lim':        np.array([0, 0.2]),\n",
    "'z_lim':        np.array([0, 0.2]),\n",
    "'x_label':      'k_ex',\n",
    "'y_label':      'k_PL',\n",
    "'z_label':      'k_LP'\n",
    "}\n",
    "\n",
    "utility.plot_spirals(data_box_spherical, plot_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Evaluating the LiMS PHT classifier\n",
    "---\n",
    "We now may proceed with the data we have created or load a data box from file which contains 40 examples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data box with 40 examples per class or keep the one already created\n",
    "load_data_from_file = True  # set to False to use new data\n",
    "if load_data_from_file:\n",
    "    # load data from previous sampling and density estimation\n",
    "    data_box_spherical = DataBox()\n",
    "    data_box_spherical = data_box_spherical.load_data('/interim/prednisone_3D_spherical_finite_mixture.pckl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess the data\n",
    "\n",
    "# make 50/50 train and test split\n",
    "labels = data_box_spherical.get_labels()\n",
    "skf = StratifiedKFold(n_splits = 2, shuffle=True, random_state=0)\n",
    "split1, split2 = skf.split(np.zeros(len(labels)), labels)\n",
    "train_index = split1[0]\n",
    "test_index = split1[1]\n",
    "labels_train = labels[train_index]\n",
    "labels_test = labels[test_index]\n",
    "data_box_spherical_train = data_box_spherical.select_examples(train_index)\n",
    "data_box_spherical_test = data_box_spherical.select_examples(test_index)\n",
    "\n",
    "# apply apply standard-score transform as preprocessing\n",
    "data_box_spherical_train_norm, means, std_devs = data_box_spherical_train.shift_and_scale_data()       # apply standard-score transform\n",
    "data_box_spherical_test_norm, _, _ = data_box_spherical_test.shift_and_scale_data(means, std_devs)     # apply the same transform to test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we evaluate the LiMS PHT classifier for the given data projected into the $(k_{PL},k_{LP})$-plane. This corresponds to a basis matrix \n",
    "$$\\mathbf{V} = \n",
    "\\begin{bmatrix}\n",
    "0 & 0 \\\\\n",
    "1 & 0 \\\\\n",
    "0 & 1 \\\\\n",
    "\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define PHT classifier and evaluate (this cell is calling on NUMBA and therefore takes longer the first time it is run ~15 seconds)\n",
    "\n",
    "# define classifier\n",
    "classifier = LiMSClassifier(None)\n",
    "\n",
    "# define a class prior\n",
    "class_prior = np.array([0.5, 0.5])\n",
    "\n",
    "# define basis matrix\n",
    "V = np.array([[0., 0.],\n",
    "              [1., 0.],\n",
    "              [0., 1.]])\n",
    "\n",
    "# make predictions for training and test data\n",
    "pht_predictions_train = classifier.eval_pht_classifier(data_box_spherical_train_norm, data_box_spherical_train_norm, class_prior, V)\n",
    "pht_predictions_test = classifier.eval_pht_classifier(data_box_spherical_train_norm, data_box_spherical_test_norm, class_prior, V)\n",
    "\n",
    "# evaluate accuracies and print\n",
    "accuracy_train = utility.calc_accuracy(pht_predictions_train, labels_train)\n",
    "accuracy_test = utility.calc_accuracy(pht_predictions_test, labels_test)\n",
    "\n",
    "print('Micro avg. training accuracy: ' + str(accuracy_train[0]))\n",
    "print('Macro avg. training accuracy: ' + str(accuracy_train[1]))\n",
    "print('Micro avg. test accuracy:     ' + str(accuracy_test[0]))\n",
    "print('Macro avg. test accuracy:     ' + str(accuracy_test[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 0.775 test accuracy, we can see that the classifier is doing reasonably well when the data is projected into the subspace spanned by $\\mathbf{V}$.\n",
    "In the following, we demonstrate our subspace learning to identify more discriminative subspaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Subspace learning\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now initialize a round of subspace learning with the $(k_{PL},k_{LP})$-plane as initial subspace and try to learn a more discriminating subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set subspace learning options and run subspace learning (~ 25 seconds)\n",
    "\n",
    "# set subspace learning options\n",
    "subspace_learn_opts = {\n",
    "    'subspace_dim':                                     2,      # positive integer      \n",
    "    'cost_function':                'subspace_likelihood',      # 'subspace_likelihood', 'GLVQ', 'subspace_likelihood_gradient'\n",
    "    'ssl_approx':                                    None,      # boolean, only makes a different if 'subspace_likelihood' is selected\n",
    "    'opt_mode':                                   'batch',      # 'batch', 'iterative'\n",
    "    'init_type':                                        V,      # 'PCA', 'random'\n",
    "    'class_prior':                                 'flat',      # 'empirical', 'flat'\n",
    "    'scipy_min_method':                            'BFGS',      # 'BFGS'\n",
    "    'scipy_min_tol':                                1e-05,      # positive float\n",
    "    'scipy_min_maxiter':                              100,      # positive int\n",
    "    'scipy_min_disp':                                True,      # boolean\n",
    "}\n",
    "\n",
    "# run subspace learning\n",
    "ssl = SubspaceLearner(data_box_spherical_train_norm, subspace_learn_opts)                                                          # spherical\n",
    "data_box_spherical = ssl.run_subspace_learning()\n",
    "subspace_learned = data_box_spherical.get_subspace_learned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for training and test data\n",
    "pht_predictions_train = classifier.eval_pht_classifier(data_box_spherical_train_norm, data_box_spherical_train_norm, class_prior, subspace_learned['V_opt'])\n",
    "pht_predictions_test = classifier.eval_pht_classifier(data_box_spherical_train_norm, data_box_spherical_test_norm, class_prior, subspace_learned['V_opt'])\n",
    "\n",
    "# evaluate accuracies and print\n",
    "accuracy_train = utility.calc_accuracy(pht_predictions_train, labels_train)\n",
    "accuracy_test = utility.calc_accuracy(pht_predictions_test, labels_test)\n",
    "\n",
    "print('Micro avg. training accuracy: ' + str(accuracy_train[0]))\n",
    "print('Macro avg. training accuracy: ' + str(accuracy_train[1]))\n",
    "print('Micro avg. test accuracy:     ' + str(accuracy_test[0]))\n",
    "print('Macro avg. test accuracy:     ' + str(accuracy_test[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few iterations, the subspace learning algorithm converged. Indeed, we see that the classification performance is much improved when evaluating the PHT classifier on the learned subspace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
